# -*- coding: utf-8 -*-
"""ML_Task_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vty4elBbEUEfzI0iBSjMAYWmAFElGX4Q

#**Import the necessary libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,
    roc_curve, roc_auc_score
)


sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12

"""#**Loading the Dataset**"""

try:
    df = pd.read_csv("Churn_Modelling.csv")
    print("Dataset loaded successfully!")
except FileNotFoundError:
    print("Error: 'Churn_Modelling.csv' not found. Please place the file in the same directory.")
    exit()

df.head()

df.shape

df.dtypes

"""#**Data Cleaning**

Drop columns that are not useful for prediction (e.g., identifiers)
"""

df = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])

df.dtypes

"""#**EDA (Exploratory Data Analysis)**"""

print("\n--- EDA: Initial Overview ---")
print(df.info())
print("\nStatistical Summary of Numerical Features:")
print(df.describe())

"""Check for class imbalance in the target variable"""

print("\nChurn Distribution:")
churn_counts = df['Exited'].value_counts()
print(churn_counts)
print(f"Percentage of Churned Customers: {(churn_counts[1] / len(df) * 100):.2f}%")

"""Visualize the churn distribution"""

plt.figure()
sns.countplot(x='Exited', data=df)
plt.title('Distribution of Churn (0: Not Exited, 1: Exited)')
plt.savefig('churn_distribution.png')
plt.show()

"""**EDA: Feature Analysis**

Analyze numerical features vs. churn
"""

numerical_features = df.select_dtypes(include=np.number).columns.drop('Exited')
for col in numerical_features:
    plt.figure()
    sns.histplot(df, x=col, hue='Exited', multiple='dodge', kde=True)
    plt.title(f'Distribution of {col} by Churn Status')
    plt.savefig(f'EDA_{col}_distribution.png')
    plt.show()

"""Analyze categorical features vs. churn"""

categorical_features = df.select_dtypes(include='object').columns
for col in categorical_features:
    plt.figure()
    sns.countplot(x=col, hue='Exited', data=df)
    plt.title(f'Churn Rate by {col}')
    plt.savefig(f'EDA_{col}_churn_rate.png')
    plt.show()

"""Check correlation matrix for numerical features"""

plt.figure(figsize=(12, 10))
corr_matrix = df[numerical_features].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix of Numerical Features')
plt.savefig('EDA_correlation_matrix.png')
plt.show()

"""#**Data Preprocessing and Feature Engineering**"""

def engineer_features(df_in):
    """
    Creates new features from the existing ones to improve model performance.
    """
    df = df_in.copy()

    # 1. New feature: Balance to Salary Ratio (handle division by zero)
    df['BalanceSalaryRatio'] = np.where(df['EstimatedSalary'] > 0, df['Balance'] / df['EstimatedSalary'], 0)

    # 2. New feature: Age Bins (discretization of Age)
    df['Age_Bin'] = pd.cut(df['Age'], bins=[0, 30, 50, 70, 100], labels=['Young', 'Middle-Aged', 'Senior', 'Elderly'])

    # 3. New feature: Is active member with high balance
    high_balance_threshold = df['Balance'].quantile(0.75)
    df['Active_and_High_Balance'] = ((df['IsActiveMember'] == 1) & (df['Balance'] > high_balance_threshold)).astype(int)

    # 4. New feature: Credit Score by Age Interaction
    df['CreditScoreAgeInteraction'] = df['CreditScore'] * df['Age']

    return df

df_engineered = engineer_features(df)
print("\n--- Feature Engineering Completed ---")
print(df_engineered.info())

X = df_engineered.drop('Exited', axis=1)
y = df_engineered['Exited']

# Identify feature types
numerical_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

# Create preprocessing pipelines for numerical and categorical data
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Create a preprocessor to apply transformations
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ],
    remainder='passthrough'
)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("\nData split into training and testing sets.")

print("Training  set shape:", X_train.shape)
print("Testing set  shape:", X_test.shape)

"""#**Model Training**"""

models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
}
results = {}
feature_importances_data = {}

"""Training and Evaluating Models"""

for name, model in models.items():
    print(f"Training {name}...")

    # Create a full pipeline for each model
    full_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                    ('classifier', model)])

    full_pipeline.fit(X_train, y_train)
    y_pred = full_pipeline.predict(X_test)
    y_proba = full_pipeline.predict_proba(X_test)[:, 1]

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba)

    results[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'ROC-AUC': roc_auc
    }

    # Save feature importance for tree-based models
    if name in ['Random Forest', 'XGBoost']:
        classifier = full_pipeline.named_steps['classifier']

        # Get feature names after one-hot encoding and new features
        ohe_feature_names = full_pipeline.named_steps['preprocessor']\
                                .named_transformers_['cat']\
                                .get_feature_names_out(categorical_cols)
        all_feature_names = numerical_cols + list(ohe_feature_names)

        importances = classifier.feature_importances_
        feature_importances_data[name] = pd.DataFrame({
            'feature': all_feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)

"""model comparison table"""

print("\n--- Model Performance Comparison ---")
results_df = pd.DataFrame(results).T
print(results_df)

"""#**Generating Predictions & Exporting Results**

Select the best model based on ROC-AUC
"""

best_model_name = results_df['ROC-AUC'].idxmax()
best_model = models[best_model_name]
print(f"\nSelected '{best_model_name}' as the best model for final export.")

# Re-run pipeline for best model
best_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                ('classifier', best_model)])
best_pipeline.fit(X_train, y_train)

# Get predictions and probabilities for the test set
final_y_pred = best_pipeline.predict(X_test)
final_y_proba = best_pipeline.predict_proba(X_test)[:, 1]

# Create a dataframe for Power BI export
export_df = X_test.copy()
export_df['Actual_Churn'] = y_test
export_df['Predicted_Churn'] = final_y_pred
export_df['Churn_Probability'] = final_y_proba

# Export the dataframe to a CSV file
export_df.to_csv('customer_churn_insights.csv', index=False)
print("Exported 'customer_churn_insights.csv' for Power BI dashboard.")

"""#**Export Feature Importances**

Export feature importance data for the tree-based models
"""

for name, importance_df in feature_importances_data.items():
    file_name = f'feature_importance_{name.replace(" ", "_").lower()}.csv'
    importance_df.to_csv(file_name, index=False)
    print(f"Exported '{file_name}' for feature importance visualization.")

print("\n--- Exporting Logistic Regression Coefficients ---")
# Get the Logistic Regression model from the pipeline
log_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                               ('classifier', models['Logistic Regression'])])
log_pipeline.fit(X_train, y_train)
log_classifier = log_pipeline.named_steps['classifier']

# Get feature names after preprocessing
ohe_feature_names = log_pipeline.named_steps['preprocessor']\
                               .named_transformers_['cat']\
                               .get_feature_names_out(categorical_cols)
all_feature_names = numerical_cols + list(ohe_feature_names)

# Get the coefficients (which represent importance)
coefficients = log_classifier.coef_[0]

# Create and export a DataFrame
log_importance_df = pd.DataFrame({
    'feature': all_feature_names,
    'coefficient': coefficients
}).sort_values('coefficient', key=abs, ascending=False)

log_importance_df.to_csv('feature_importance_logistic_regression.csv', index=False)
print("Exported 'feature_importance_logistic_regression.csv'.")

"""feature importance for the best model (if it's tree-based)

"""

if best_model_name in feature_importances_data:
    plt.figure(figsize=(10, 8))
    top_features = feature_importances_data[best_model_name].head(15)
    sns.barplot(x='importance', y='feature', data=top_features, palette='viridis')
    plt.title(f'Top 15 Feature Importances for {best_model_name}')
    plt.xlabel('Importance Score')
    plt.ylabel('Feature')
    plt.tight_layout()
    plt.savefig('best_model_feature_importance.png')
    plt.show()